{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASKS\n",
    "\n",
    "\n",
    "This notebook contains the four tasks for this module.  \n",
    "Each task contains a different problem to solve, organized into separate and different sections for greater organization.\n",
    "\n",
    "<u>The notebook structure</u> for each task contains the following sections:\n",
    "\n",
    "1) **Task statement**  \n",
    "   Includes the description of the task.\n",
    "2) **Information about the task, explanation and approach used**  \n",
    "   Here the information on the task is given in more detail, what theoretical elements it contains and how it will be carried out.  \n",
    "3) **Resolution**  \n",
    "   Here is the part of the code related to data analysis.\n",
    "4) **Analysis results**  \n",
    "   After the calculations, the conclusions and the data visualization part are established.\n",
    "5) **References**  \n",
    "   Links to the material used.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports  \n",
    "\n",
    "Since this document contains various tasks, I have chosen to import the libraries at the beginning of the document, for greater organization and efficiency in loading times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats  \n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To maintain the readability of the notebook, I remove the warnings that may appear.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task nº1 - Lady Tasting Tea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task statement\n",
    "\n",
    "Suppose we alter the Lady Tasting Tea experiment to involve twelve cups of tea. Six have the milk in first and the other six having tea in first. A person claims they have the special power of being able to tell whether the tea or the milk went into a cup first upon tasting it. You agree to accept their claim if they can tell which of the six cups in your experiment had the milk in first.\n",
    "\n",
    "Calculate, using Python, the probability that they select the correct six cups. Here you should assume that they have no special powers in figuring it out, that they are just guessing. Remember to show and justify your workings in code and MarkDown cells.\n",
    "\n",
    "Suppose, now, you are willing to accept one error. Once they select the six cups they think had the milk in first, you will give them the benefit of the doubt should they have selected at least five of the correct cups. Calculate the probability, assuming they have no special powers, that the person makes at most one error.\n",
    "\n",
    "Would you accept two errors? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the task, explanation and approach used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment presented as task number one is a variation on one of the many statistical problems contained in the book called \"The Design of Experiments\" which was written in 1935 by the English statistician **Ronald Fisher**, on the design of experiments and is considered a fundamental work in experimental design and in modern statistical science.\n",
    "\n",
    "In this experiment, Fisher introduced the concept of the null hypothesis into the framework of hypothesis testing as part of his approach to the analysis of experiments.\n",
    "\n",
    "This procedure can be applied in many contexts, and is a fundamental basis in statistics for making data-based decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the application of this theory in the experiment, I am going to indicate a brief description of the null hypothesis and its application to this case.\n",
    "\n",
    "The null hypothesis (H₀) and the alternative hypothesis (H₁) are basic concepts used in inferential statistics for decision making.\n",
    "\n",
    "We try to find evidence to support or refute assumptions or statements.\n",
    "\n",
    "\\begin{align*}\n",
    "H_0 &: \\theta = \\theta_0 \\\\\n",
    "H_1 &: \\theta \\neq \\theta_0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis (H₀)**: It is the initial statement that is assumed to be true until proven otherwise.  \n",
    "Applied to our experiment, it may consist of the assumption that the person drinking tea does not have any sixth sense, that is, that person guesses how that tea was prepared.\n",
    "\n",
    "The **alternative hypothesis((H₁))** is the statement contrary to the null hypothesis, that is, it is what the experiment is trying to prove.  \n",
    "In our example, the person has a gift that goes beyond good luck, he is quite a fortune teller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, we can choose between the use of permutations or combinations, however I will opt for the use of combinations, since the problem establishes that the order of the cups is not important and the combinations are preferable because it is only interesting the selection of cups, not the order.  \n",
    "\n",
    "The formula used for the combinations is the following:  \n",
    "\n",
    "$$\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$$ \n",
    "\n",
    "where:  \n",
    "\n",
    "\"n\" is the number of elements, and i this particular example is 12  \n",
    "\"k\" is the number of selected elements,6 cups that have the milk first  \n",
    "$\\binom{n}{k}$ is the number of ways to choose \"k\" elements on a set of \"n\" elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the evidence against the null hypothesis, a concept called **p - value** is used.\n",
    "\n",
    "If the p value meets the condition of being less than an arbitrarily imposed significance level, this is considered a statistically significant result and, therefore, allows us to reject the null hypothesis.  \n",
    "\n",
    "The significance level \"α\" is a threshold that is chosen in advance before performing the experiment and is commonly set at 0.05 (5%).  \n",
    "This means that a 5% probability of incorrectly rejecting the null hypothesis is accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code part,I am going to use several functionalities of the python numpy library and the matplotlib library to more directly visualize the results of my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "1) For this experiment we have 12 cups of tea of  ​​which 6 have milk first and the remaining ones have tea first.\n",
    "2) A person claims they have the special power of being able to tell whether the tea or the milk went into a cup first upon tasting it.\n",
    "3) Calculate the probability that the person guesses all the cups by chance. This is our null hypothesis(the person does not have any special skill).\n",
    "4) Calculate the probability, assuming they have no special powers, that the person makes at most one error(correctly select 5 cups out of 6).\n",
    "5) The order when guessing the cups is not important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution\n",
    "\n",
    "Numpy and matplotlib libraries are used for this task.  \n",
    "Variables are now set and with them I calculate the combinations by calculating the probability that the person choose the correct 6 cups by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cups = 12\n",
    "correct_cups = 6  # 6 cups that have the milk first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of factorial products for the calculation of combinations.\n",
    "def combinations(n, k):\n",
    "    return np.prod(np.arange(n - k + 1, n + 1)) // np.prod(np.arange(1, k + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"n\" and \"k\" instead of the variables we created at the beginning, I can modify the number of cups if I want.  \n",
    "Now I calculate the total of possible combinations and the probability that the person has to choose the correct 6 in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combinations = combinations(total_cups, correct_cups)\n",
    "prob_correct = 1 / total_combinations\n",
    "print(f\"The number of possible combinations is : {total_combinations}\")\n",
    "print(f\"The probability that they select the correct six cups: {prob_correct:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, it gives us a probability of 0.108225% that it is correct when choosing the 6 cups among all the available combinations.  \n",
    "\n",
    "\n",
    "To evaluate our hypothesis I use the p value mentioned above and compare it with the obtained result.  \n",
    "  \n",
    "\n",
    "If p < α I reject the null hypothesis  \n",
    "\n",
    "As \"p\" in the example is 0,00108 and \"α\" is 0,05 that means 0,00108 < 0,05 **the null hypothesis would be rejected.**  \n",
    "\n",
    "I reject the null hypothesis in favor of the alternative hypothesis, indicating that the person who tastes the teas has a special ability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second part of the problem, it is stated that the person makes at most one error and that he does not have special skills, that is, that he chooses at least 5 cups correctly.  \n",
    "Since it is one cup less, the probability will be greater, but I will have to calculate it to know if this time I reject the null hypothesis again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the number of ways in which 5 correct cups and 1 incorrect cup can be chosen\n",
    "comb_5_correct = combinations(correct_cups, 5) * combinations(total_cups - correct_cups, 1) \n",
    "prob_5_correct = (comb_5_correct + 1) / total_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem also asks if I could accept 2 errors, so I am going to calculate this new situation and then compare it with the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the number of ways in which 4 correct cups and 2 incorrect cup can be chosen\n",
    "comb_4_correct = combinations(correct_cups, 4) * combinations(total_cups - correct_cups, 2)\n",
    "prob_4_correct = comb_4_correct / total_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the calculations done, tt's time to interpret the results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis results\n",
    "A compilation of the results to establish which hypotheses are rejected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The probability of selecting the correct six cups: {prob_correct:.5f}\")\n",
    "print(f\"The probability of selecting 5 cups correctly with 1 error: {prob_5_correct:.5f}\")\n",
    "print(f\"The probability of selecting 4 cups correctly with 2 errors : {prob_4_correct:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first option, I rejected the null hypothesis.  \n",
    "For the second option, as 0.04004 < 0.05 I also reject the null hypothesis.  \n",
    "For the last option,  0.24351 > 0.05 , so in this case the null hypothesis is not rejected.  \n",
    "This means that it is possible for a participant who has no special skills to guess 4 cups correctly by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first and second cases, the probability is very low, suggesting that the person does not have any special abilities.\n",
    "However, for the third option, it is possible but not totally certain that by accepting 2 errors, the person has special abilities.  \n",
    "I could consider accepting 2 errors with the probability of 24.351% but the fact that one has special powers is not conclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to use matplotlib to compare the probability of getting the cups correct with the different scenarios analyzed, that is, with 0, 1 or 2 errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities and labels for the graph\n",
    "labels = [\"6 correct\", \"5 correct and 1 error\", \"4 correct and 2 errors\"]\n",
    "probs = [prob_correct, prob_5_correct, prob_4_correct]\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(labels, probs, color=[\"green\", \"yellow\", \"red\"])\n",
    "plt.ylabel(\"Probabilities\")\n",
    "plt.title(\"Probability of correct cups selections with different errors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization tells us in a direct and concise way the enormous difference that exists between the 3 scenarios analyzed.\n",
    "\n",
    "### References\n",
    "\n",
    "https://numpy.org/devdocs/reference/generated/numpy.arange.html  \n",
    "https://numpy.org/doc/stable/reference/generated/numpy.prod.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task nº2 - Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task statement\n",
    "\n",
    "In this task you will assess whether `numpy.random.normal()` properly generates normal values.  \n",
    "To begin, generate a sample of one hundred thousand values using the function with mean 10.0 and standard deviation 3.0.\n",
    "\n",
    "Use the `scipy.stats.shapiro()` function to test whether your sample came from a normal distribution. Explain the results and output.\n",
    "\n",
    "Plot a histogram of your values and plot the corresponding normal distribution probability density function on top of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the task, explanation and approach used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task asks to use functionalities from the python library called numpy, which I  had used in the nº 1 task, applied to the normal probability distribution.  \n",
    "\n",
    "The Normal Distribution is one of the most important probability distributions in statistics and has its name given its high frequency in natural phenomena, such as the height or weight of a population.  \n",
    "\n",
    "It is also known as the \"Bell curve\" or \"Gaussian bell\" due to its characteristic shape, as it tends to group around a central value with a certain symmetry in its variations.  \n",
    "Its key characteristics are its mean or average and the standard deviation, which tells us how wide or narrow the campaign is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These values ​​are parameters found in the density function, which indicates how the values ​​of a continuous variable are distributed, that is, how likely it is that the values ​​of a continuous variable fall into a certain interval.\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}\n",
    "$$\n",
    "\n",
    "μ is the mean of the distribution  \n",
    "σ is the standard deviation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula is useful for the Calculation of Probabilities in Intervals, for the prediction of probable values ​​or its use in probabilistic models, among other uses.\n",
    "\n",
    "As I had mentioned, the use of this distribution is so common that for example it appears in popular culture such as the book Jurassic Park, written by Michael Crichton.  \n",
    "In this book, the matematician Ian Malcom, after viewing some data collected from a computer, explains that while any healthy biological population typically presents a normal distribution, the created dinosaur population on the island should never follow that pattern , as the creators manipulated the values ​​by creating them artificially and in a controlled environment.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "1) Check if the function numpy.random.normal() correctly generates normal values.  \n",
    "2) A sample of one hundred thousand values ​​will be generated using the function with a mean of 10.0 and a standard deviation of 3.0.  \n",
    "3) The scipy.stats.shapiro() function will be used to test if the sample comes from a normal distribution.  \n",
    "4) A histogram of the generated values ​​must be created and overlaid with the probability density function of the corresponding normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution\n",
    "\n",
    "For the task, I use the numpy libraries, matplotlib.pyplot and scipy.stats, for the statistics part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample of one hundred thousand values using the function with mean 10.0 and standard deviation 3.0\n",
    "mean = 10.0\n",
    "std_dev = 3.0\n",
    "sample_size = 100000\n",
    "sample = np.random.normal(loc=mean, scale=std_dev, size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check whether the sample came from a normal distribution\n",
    "shapiro_test_stat, p_value = stats.shapiro(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Shapiro Test:\", shapiro_test_stat)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis results\n",
    "\n",
    "The Shapiro test is very close to having a value of 1. Furthermore, the p value obtained is much higher than the usual value of 0.0, which suggests that the sample follows a normal distribution, a plausible and expected result since the function used to generate the sample is `np.random.normal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the exercise asks you to make a graph of the sample and create a line corresponding to the density function of the superimposed normal distribution, in order to check its shape and how far it is from a perfect normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram from the generated sample\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(sample, bins=50, density=True, alpha=0.6, color=\"blue\", edgecolor=\"black\", label=\"Sample\")\n",
    "\n",
    "# Density curve interval\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "p = stats.norm.pdf(x, mean, std_dev)\n",
    "\n",
    "# Combine both\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Sample Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, the fit is almost perfect.\n",
    "The combined plot clearly suggests that the sample generated through `np.random.normal` has a good fit to a normal distribution, given the mean and standard deviation. The data are distributed around the value 10 and the dispersion is 3 units around the mean.\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html  \n",
    "https://numpy.org/devdocs/reference/generated/numpy.linspace.html  \n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy-random-normal  \n",
    "https://docs.python.org/3/library/warnings.html#warnings.filterwarnings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task nº3 - t-Test Calculation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following dataset containing resting heart rates for patients before and after embarking on a two-week exercise program.  \n",
    "| Patient ID | 0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  |\n",
    "|------------|----|----|----|----|----|----|----|----|----|----|\n",
    "| Before     | 63 | 68 | 70 | 64 | 74 | 67 | 70 | 57 | 66 | 65 |\n",
    "| After      | 64 | 64 | 68 | 64 | 73 | 70 | 72 | 54 | 61 | 63 |  \n",
    "\n",
    "\n",
    "Calculate the t-statistic based on this data set, using Python. Compare it to the value given by `scipy.stats`. Explain your work and list any sources used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the task, explanation and approach used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercises, a slight introduction has been given to the elements used in statistical inference, such as the normal distribution and hypothesis testing.\n",
    "Now, for this exercise we present the t-statistic, which is a value that serves as a test to know if the difference between the response of two groups is statistically significant or not.  \n",
    "\n",
    "This statistic is based on the student t distribution, which shares similarities with the normal distribution, since both are continuous, have a bell shape or their standardized mean is equal to 0, however the tails or edges of the t distribution are more coarse, due to the additional uncertainty generated by the lack of knowledge of the sample variance.  \n",
    "\n",
    "Having already used the normal distribution, the t distribution is used for this assumption since the sample is much smaller and the population variance is unknown.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general formula is the following:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "#### Where:\n",
    "- $t$ :Student's t statistic.\n",
    "- $\\bar{x}$ :Sample mean.\n",
    "- $\\mu$ :Population mean (Using the null hypothesis).\n",
    "- $s$ :Sample Standard deviation.\n",
    "- $n$ :Sample size.  \n",
    "\n",
    "This formula is not comparing pairs of data, but rather the sample against a fixed value.  \n",
    "\n",
    "Because of this, for the data offered it is better to use the t-statistic for related samples,which formula is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "#### Where:\n",
    "- $t$ :Value of the t-statistic.\n",
    "- $\\bar{d}$ :Mean of the differences\n",
    "- $s_d$ :Standard deviation of the differences\n",
    "- $n$  Number of paired data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement  \n",
    "\n",
    "1) Compare the heart rate data of a group of 10 people. \n",
    "2) The program gives measurements before and after a physical training program.  \n",
    "3) Therefore, faced with the two groups of observations, before and after, two arrays can be created to facilitate manipulation.\n",
    "4) Differences must be calculated to obtain the rest of the necessary data.  \n",
    "5) Finally alculate the t statistic to later compare it with the values ​​generated by scipy.stats.  \n",
    "6) Compare results and conclusions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution  \n",
    "\n",
    "The necessary libraries have already been imported at the beginning of the notebook, but I present a brief compilation to indicate what the purpose of each one is.  \n",
    "\n",
    "`Numpy` I use it to create arrays of the data, one for the data grouped \"before\" and another for the data \"after\".  \n",
    "`scipy.stats` Using this statistical library, the value to be compared of the statistic t will be directly calculated.  \n",
    "`matplotlib.pyplot` To make graphs of the data obtained and help draw conclusions visually.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the two groups\n",
    "before = np.array([63, 68, 70, 64, 74, 67, 70, 57, 66, 65])\n",
    "after = np.array([64, 64, 68, 64, 73, 70, 72, 54, 61, 63])\n",
    "\n",
    "# Checking the differences\n",
    "difference = before - after  \n",
    "\n",
    "# Calculate mean and standard desviation\n",
    "mean_diff = np.mean(difference)\n",
    "std_diff = np.std(difference) \n",
    "\n",
    "# Using the t formula for the related samples\n",
    "n = len(difference)\n",
    "t_stat_manual = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "print(t_stat_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have calculated t manually, I will use `scipy.stats.ttest_rel` that calculates both the value t and the p- value, which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_scipy, p_value = stats.ttest_rel(before, after)\n",
    "print(t_stat_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the result of both has been calculated, it is time to compare it.  \n",
    "The first result was obtained by manually calculating variables such as the mean and standard deviation and then applying it to the formula.\n",
    "In the second case, it was calculated automatically with the corresponding functionality of the scipy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(t_stat_manual)\n",
    "print(t_stat_scipy)\n",
    "difference_stats = t_stat_manual - t_stat_scipy \n",
    "print(\"The difference between the two measurements is:\", difference_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is quite small between both calculations.\n",
    "For this specific exercise where we calculate the difference between the heartbeats of a sample after a training program, this t value will help us decide if the exercise program was a determining factor for the subjects to reduce their heartbeats or it was all due to a product of chance.  \n",
    "\n",
    "To really verify the above, I can establish a hypothesis, using the hypothesis test explained in the previous exercise.  \n",
    "The hypotheses focus on whether the exercise program had a significant effect on the resting heart rates of the participants and will be found based on the means of the differences.  \n",
    "I am going to use the two-tailed test approach for the hypothesis.\n",
    "\n",
    "1) The null hypothesis declares that the exercise did not had any effect to the participants\n",
    "$$H_0: \\bar{d} = 0$$\n",
    "\n",
    "2) The alternative hypothesis declares that the exercise had a significant effect by reducing the heart rate\n",
    "$$H_1: \\bar{d} \\neq 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using again the p-value with a significance level of 5% (that is, the p-value is 0.05) implying a confidence level of 95%, I need to calculate the p- value associated with the value \"t\" in order to compare and check the hypothesis.  \n",
    "I have previously calculated the t-statistic in two ways, apart from the associated p-value.  \n",
    "I have the following as a t statistic and its associated p value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(f\"The t-statistic is {t_stat_scipy:.3f} and its associated p-value is {p_value:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the result with a 5% significance level:\n",
    "\n",
    "p= 0.213 > 0.05 : **The null hypothesis is not rejected.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that with the result obtained there is not enough evidence to draw a solid and accurate conclusion that the 2-week exercise program has a significant change in the resting heartbeats of the participants.  \n",
    "\n",
    "One way to visually see these few changes can be through the following graph, which indicates how the data varies before and after the exercise program. This graph will allow you to visualize how the data varies before and after the exercise program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute differences\n",
    "differences = np.array(after) - np.array(before)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(differences, bins=5, color=\"red\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Differences (After - Before)\")\n",
    "plt.xlabel(\"Difference in Heart Rate\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task shows us in a simplified way a small population and changes in resting heart rate after a training system and although the result cannot be verified, there are numerous studies where other health parameters such as VO2max, or the maximum amount of oxygen that the body can process,takes a lot of importance.\n",
    "\n",
    "This parameter is a fundamental indicator of health, as indicated by the American Heart Association[1], or a study[2] carried out in 2018 that evaluated 120,000 people and in from which the researchers concluded that having low cardiorespiratory capacity posed a much higher risk than other classic factors, such as hypertension, smoking or high cholesterol, in reducing vitality.  \n",
    "\n",
    "### References\n",
    "\n",
    "https://www.investopedia.com/terms/t/t-test.asp  \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html#ttest-rel  \n",
    "https://www.ahajournals.org/doi/full/10.1161/CIR.0000000000000461 [1]  \n",
    "https://pubmed.ncbi.nlm.nih.gov/30646252/ [2]\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task nº4 - ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test I will estimate the probability of committing a type II error in specific circumstances.\n",
    "To begin, create a variable called no_type_ii and set it to 0.\n",
    "\n",
    "Now use a loop to perform the following test 10,000 times.\n",
    "\n",
    "1. Use numpy.random.normal to generate three samples with 100 values each.  \n",
    "   Give each a standard deviation of 0.1.  \n",
    "   Give the first sample a mean of 4.9, the second a mean of 5.0, and the third a mean of 5.1. \n",
    "\n",
    "2. Perform one-way anova on the three samples and add 1 to no_type_ii whenever a type II error occurs.\n",
    "\n",
    "Summarize and explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the task, explanation and approach used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise I focused on the use of the t statistic and now this exercise focuses on ANOVA.\n",
    "\n",
    "**ANOVA (Analysis of Variance)** is a statistical technique that is used to compare the means of three or more groups and determine if there are significant differences between them. Evaluate variability within and between groups to verify whether observed differences are due to specific factors or chance.  \n",
    "It is based on the relationship between the explained variance (between groups) and the unexplained variance (within groups), expressed by a statistic called 𝐹.  \n",
    "This statistic is commonly used in experiments and studies with multiple categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use ANOVA for this exercise since I want to compare the means of three groups to check if there are statistically significant differences.  \n",
    "It is an alternative to performing multiple t tests, which increases the risk of type I errors.  \n",
    "The exercise talks about making two types of errors, which are explained below:\n",
    "\n",
    "1) **Type I error**: Occurs if we reject the null hypothesis when it is actually true (false positive). The level of significance (α) controls this error.\n",
    "2) **Type II error**: This error occurs when we do not reject the null hypothesis even though there is a real difference between the means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **𝐹 statistic** is defined as the ratio of two variances:\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variability (MSB)}}{\\text{Within-group variability (MSW)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **MSB (Mean Square Between):** Represents the variability between group means, i.e., how much the group means differ from each other.\n",
    "- **MSW (Mean Square Within):** Represents the variability within individual groups, i.e., how much the data varies within each group due to random noise or experimental error.  \n",
    "\n",
    "The statistic called 𝐹 helps us evaluate whether the differences in group means are large enough to reject the null hypothesis.  \n",
    "A type II error occurs when the value of 𝐹 is not large enough (or the p value is greater than α) to detect real differences between the groups, thus avoiding rejecting the null hypothesis.  \n",
    "\n",
    "Once this new approach has been presented, I move on to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement  \n",
    "\n",
    "1) Define initial variable no_type_ and count cases where a type II error occurs.  \n",
    "2) Use numpy.random.normal to generate three samples with given means and same standard deviation of 0.1  \n",
    "3) Use scipy.stats.f_oneway to perform a one-way ANOVA. This gives us the p value for comparing for reject or not the null hypothesis.\n",
    "4) Record type II errors if we do not reject the null hypothesis.  \n",
    "5) Repeat this procedure 10,000 times to count how many times we get the type II error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution  \n",
    "\n",
    "As in the previous exercise, I present in this section the libraries that are used for this exercise and that have been imported at the beginning of the document:  \n",
    "\n",
    "`Numpy` I use it to generate three samples with given means and same standard deviation of 0.1  \n",
    "`scipy.stats` Using this statistical library to perform a one-way ANOVA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variable to count type II errors\n",
    "error_type_ii = 0\n",
    "\n",
    "# Number of simulations\n",
    "simulations = 10000\n",
    "\n",
    "# Loop to perform the test 10,000 times\n",
    "for _ in range(simulations):\n",
    "    # Generate three samples with given means and standard deviation\n",
    "    sample1 = np.random.normal(loc=4.9, scale=0.1, size=100)\n",
    "    sample2 = np.random.normal(loc=5.0, scale=0.1, size=100)\n",
    "    sample3 = np.random.normal(loc=5.1, scale=0.1, size=100)\n",
    "\n",
    "    # One-way ANOVA\n",
    "    f_statistic, p_value = stats.f_oneway(sample1, sample2, sample3)\n",
    "\n",
    "    # Type II error: Failing to reject the null hypothesis when it is false\n",
    "    if p_value > 0.05:  # Significance level at 95%\n",
    "        error_type_ii = error_type_ii + 1\n",
    "    else:\n",
    "        pass  # Do nothing if the null hypothesis is rejected\n",
    "\n",
    "# Calculate and print the probability of a type II error\n",
    "probability_type_ii = error_type_ii / simulations\n",
    "print(f\"Number of type II errors: {error_type_ii}\")\n",
    "print(f\"Probability of committing a type II error: {probability_type_ii:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result gives an expected result, since the sample size is large (n=100) and the difference between the means of the 3 samples is minimal (a difference of + and - 0.1). \n",
    "Therefore, the ANOVA test detects well the differences generated between the samples.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
